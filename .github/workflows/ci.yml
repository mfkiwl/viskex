name: viskex CI

on:
  push:
    branches:
      - "**"
  pull_request:
    branches:
      - main
  schedule:
    - cron: "0 21 * * SUN"
  workflow_dispatch:

jobs:
  test:
    if: >-
      (
        (
          github.event_name == 'schedule'
          && github.repository == 'viskex/viskex'
        ) || (
            github.event_name != 'schedule'
            && !(
              contains(github.event.head_commit.message, '[ci skip]')
              || contains(github.event.head_commit.message, '[skip ci]')
            )
        )
      )
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - backend: dolfinx
            container: dolfinx/dolfinx:nightly
            setup_container:
          - backend: firedrake
            container: firedrakeproject/firedrake
            setup_container: |
              export DEBIAN_FRONTEND="noninteractive"
              apt -y -qq update
              apt install -y -qq xorg
              echo "/home/firedrake/firedrake/bin" >> $GITHUB_PATH
      fail-fast: false
    container:
      image: ${{ matrix.container }}
      options: --user root
    steps:
      - uses: actions/checkout@v3
      - name: Setup container
        run: ${{ matrix.setup_container }}
      - name: Determine which steps to skip
        id: skips
        run: |
          echo "run_unit_tests=false" >> $GITHUB_OUTPUT
          echo "run_coverage=false" >> $GITHUB_OUTPUT
          echo "publish_to_website=false" >> $GITHUB_OUTPUT
      - name: Install viskex
        run: python3 -m pip install .[docs,lint,tests,tutorials]
      - name: Update mypy configuration
        run: |
          if [[ "${{ matrix.backend }}" == "dolfinx" ]]; then
            sed -i 's@exclude = (^\\\.eggs|^build|^dist|conftest\\\.py\$)@exclude = (^\\\.eggs|^build|^dist|conftest\\\.py\$|^viskex/firedrake_plotter\\\.py\$)@g' setup.cfg
            echo "[tool.nbqa.exclude]" >> pyproject.toml
            echo 'mypy = "^tutorials/.*/tutorial_.*_firedrake"' >> pyproject.toml
          elif [[ "${{ matrix.backend }}" == "firedrake" ]]; then
            echo "[mypy-dolfinx]" >> setup.cfg
            echo "ignore_missing_imports = True" >> setup.cfg
            echo "[mypy-dolfinx.*]" >> setup.cfg
            echo "ignore_missing_imports = True" >> setup.cfg
            sed -i 's@exclude = (^\\\.eggs|^build|^dist|conftest\\\.py\$)@exclude = (^\\\.eggs|^build|^dist|conftest\\\.py\$|^viskex/dolfinx_plotter\\\.py\$)@g' setup.cfg
            echo "[tool.nbqa.exclude]" >> pyproject.toml
            echo 'mypy = "^tutorials/.*/tutorial_.*_dolfinx"' >> pyproject.toml
          else
            echo "Invalid backend"
            exit 1
          fi
        shell: bash
      - name: Run flake8 and mypy checks on python files
        run: |
          python3 -m flake8 .
          python3 -m mypy .
      - name: Run documentation generation
        run: |
          cd docs && make html
      - name: Run unit tests
        if: steps.skips.outputs.run_unit_tests != 'false'
        run: |
          COVERAGE_FILE=.coverage_unit_${{ matrix.backend }} python3 -m pytest --cov=viskex --cov-report= tests/unit
      - name: Run flake8 and mypy checks on tutorial files
        run: |
          NO_TESTS_COLLECTED=5
          python3 -m pytest --ipynb-action=create-notebooks tutorials || (($?==$NO_TESTS_COLLECTED))
          python3 -m nbqa flake8 .
          python3 -m nbqa mypy .
        shell: bash
      - name: Check for stray outputs, counts and metadata in ipynb files
        uses: RBniCS/check-jupyter-metadata-action@main
        with:
          pattern: "tutorials/**/*.ipynb"
      - name: Run tutorials
        run: |
          COVERAGE_FILE=.coverage_tutorials_${{ matrix.backend }} python3 -m pytest --cov=viskex --cov-report= tutorials
      - name: Store coverage reports as artifact
        if: steps.skips.outputs.run_coverage != 'false'
        uses: actions/upload-artifact@v2
        with:
          name: coverage-${{ matrix.backend }}
          path: |
            .coverage_unit_${{ matrix.backend }}
            .coverage_tutorials_${{ matrix.backend }}
          retention-days: 1
      - name: Upload tutorials logs as an artifact in case of failure
        if: failure() || cancelled()
        uses: actions/upload-artifact@v2
        with:
          name: "tutorials-logs-${{ matrix.backend }}"
          path: |
            tutorials/**/.ipynb_pytest/**/*.log*
      - name: Clone website repository
        if: steps.skips.outputs.publish_to_website != 'false'
        uses: actions/checkout@v3
        with:
          repository: viskex/viskex.github.io
          path: _website
      - name: Copy jupyter template from website repository
        if: steps.skips.outputs.publish_to_website != 'false'
        run: |
          jupyter --paths --json > /tmp/jupyter-paths
          JUPYTER_SHARE=$(python3 -c 'import json; data = json.loads(open("/tmp/jupyter-paths", "r").read()); print(data["data"][1])')
          python3 -m pip -q install nbconvert
          mkdir -p $JUPYTER_SHARE/nbconvert/templates
          cp -rf _website/share/jupyter/nbconvert/templates/html/viskex $JUPYTER_SHARE/nbconvert/templates/
          rm /tmp/jupyter-paths
      - name: Convert notebooks to html
        if: steps.skips.outputs.publish_to_website != 'false'
        run: |
          readarray -d '' LIST_NOTEBOOKS < <(find . -type f -not -path "*.ipynb_pytest*" -name "tutorial_*_${{ matrix.backend }}.ipynb" -print0)
          mkdir -p _build/html
          for SRC in "${LIST_NOTEBOOKS[@]}"; do
              pushd $(dirname "$SRC")
              jupyter nbconvert --to html --template viskex --execute --output-dir $GITHUB_WORKSPACE/_build/html/$(dirname "$SRC") $(basename "$SRC")
              popd
          done
        shell: bash
      - name: Store converted notebooks as artifacts
        if: steps.skips.outputs.publish_to_website != 'false'
        uses: actions/upload-artifact@v2
        with:
          name: converted-notebooks-${{ matrix.backend }}
          path: _build/html
          retention-days: 1
      - name: Warn if scheduled workflow is about to be disabled
        if: github.repository == 'viskex/viskex' && github.ref == 'refs/heads/main' && github.event_name == 'schedule'
        uses: fem-on-colab/warn-workflow-about-to-be-disabled-action@main
        with:
          workflow-filename: ci.yml
          days-elapsed: 50
    outputs:
      run_unit_tests: ${{ steps.skips.outputs.run_unit_tests }}
      run_coverage: ${{ steps.skips.outputs.run_unit_tests }}
      publish_to_website: ${{ steps.skips.outputs.run_unit_tests }}

  combine_coverage:
    runs-on: ubuntu-latest
    container: ubuntu
    needs: [test]
    if: needs.test.outputs.run_coverage != 'false'
    steps:
      - uses: actions/checkout@v3
      - name: Setup container
        run: |
          export DEBIAN_FRONTEND="noninteractive"
          apt -y -qq update
          apt install -y -qq python3-pip rsync
          python3 -m pip -q install coverage
      - name: Download coverage reports from artifacts
        uses: actions/download-artifact@v2
        with:
          path: _coverage
      - name: Flatten the artifacts hierarchy
        run: |
          rm -rf _coverage/converted-notebooks-*
          rsync -avh --remove-source-files _coverage/coverage-*/ _coverage
      - name: Combine coverage reports
        run: |
          python3 -m coverage combine _coverage/.coverage*
          python3 -m coverage report --fail-under=100 --show-missing --skip-covered

  publish_notebooks:
    runs-on: ubuntu-latest
    needs: [test]
    if: github.repository == 'viskex/viskex' && github.ref == 'refs/heads/main' && needs.test.outputs.publish_to_website != 'false'
    steps:
      - uses: actions/checkout@v3
      - name: Clone website repository
        uses: actions/checkout@v3
        with:
          repository: viskex/viskex.github.io
          token: ${{ secrets.REPO_ACCESS_TOKEN }}
          ref: gh-pages
          fetch-depth: 0
          path: _build/html
      - name: Download converted notebooks from artifacts
        uses: actions/download-artifact@v2
        with:
          path: _build/html
      - name: Flatten the artifacts hierarchy
        run: |
          rm -rf _build/html/coverage-*
          rsync -avh --remove-source-files _build/html/converted-notebooks-*/ _build/html/
          find _build/html/ -type d -empty -delete
      - name: Upload release file to website
        run: |
          SHA_SHORT=$(git rev-parse --short HEAD)
          pushd _build/html
          git config user.name "GitHub Actions"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add .
          git pull origin gh-pages
          [ -n "$(git status --porcelain=v1 2>/dev/null)" ] && git commit -m "deploy: ${GITHUB_REPOSITORY}@${SHA_SHORT}"
          git push origin gh-pages
          popd
        shell: bash
